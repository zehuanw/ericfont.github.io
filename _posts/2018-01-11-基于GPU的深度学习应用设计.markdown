---
layout: post
title: 基于GPU的深度学习应用设计
---
## 这篇文章写给哪些人
你是一个正要开始开发基于NVIDIA GPU的深度学习产品的工程师。或者已经开始开发，但是愿意回过头来重新审视自己在程序设计阶段可能存在的问题。
你将在这篇文章中了解到：好的GPU程序设计可以给我们带来什么，或者，哪些问题是可以在GPU程序设计阶段回避的；GPU程序设计阶段要考虑哪些问题；如何考虑这些问题。

你是一个正在领导深度学习产品开发的经理，并且对NVIDIA GPU的解决方案并不排斥。
你将在这篇文章中了解到：如何评估GPU可能为这个产品带来的提升；如何选出最适合于这个项目的GPU实现方案。

## 程序设计是最重要的一步，尤其对于GPU程序
我们在支持用户进行GPU相关程序开发的时候，往往会面对一些完成度很高的糟糕的实现。这些糟糕的实现往往从设计上讲就是糟糕的，比如我们总会看到循环内b部出现的内存分配（减少模块间耦合性），总会看到几百个线程的kernel（比把一些计算合并更容易实现和便于理解），总会看到一些不打batch的DNN实现（程序灵活性高，容易适配原来的CPU设计）。开发者对这些错误的设计辩护时，往往理由充分。但是，我们之所以将程序迁移到GPU，难道不是为了提高性能吗？
这些实现由于对底层实现进行了多层的封装，或者代码庞大，让我们在优化的时候感到无从下手。想要将这类应用优化到合理的水平往往需要大刀阔斧的修改，有时候甚至和重写一遍没有太大区别。

所以，那些最严重的性能问题往往都和程序设计阶段的错误有关。

GPU和CPU从硬件上有明显的区别，这些区别使得一些糟糕的程序设计可以带来极大地性能问题。举个例子:Tesla P4上YOLO Tiny的inference频率可以达到~1000fps,但是一个多余的内存分配和释放（与主机中总共显存空间，内存空间，同时调用的cudaMalloc/cudaFree的数量有关系）甚至可以达到上百毫秒。一个简单的kernel 调用，比如小图片的YUV-RGB的转换时间可能在几个微妙，但是一个kernel调用所需要的准备时间（CPU上）可以达到十几个微妙，在Tegra上甚至可以达到几十上百微秒。

所以，程序设计对整个GPU程序的性能极其重要。

## 什么是优秀的GPU程序设计
### 优秀GPU程序设计的一些共同特征
1. 优秀的GPU程序设计往往只在程序运行之初分配资源（内存，显存，创建Handle，stream等）和进行初始化操作。如果你使用面向对象的设计，就是在构造函数中进行分配和初始化。面向对象的设计可以让GPU程序设计思路更清楚也更简单。
2. 相对的，优秀的程序设计往往只在程序运行结尾进行资源的释放。比如析构函数中。
3. 优秀的程序设计往往充分考虑到GPU的并行计算优势，让每一次计算（Kernel调用）完成更多的数据处理（本质上分配更多的并行线程）。比如对于DNN来说，是打batch进行处理，同时也可以合并多个不相关的layer进行计算（参考TensorRT的特性）。对于矩阵计算就是多个同size的小矩阵一起计算。对于网格计算，就是每个GPU上分配更多网格。
4. 优秀的程序设计往往使用优化方式对数据进行存储（参考Best Practice Guide中对于合并访问的解释）。比如对于矩阵相乘来说NT的性能往往好于NN。

### 优秀的GPU程序设计也是优秀的程序设计。
在众多方面优秀的GPU程序设计和我们熟知的CPU程序设计有着很多共性。
1. 它们都是充分考虑应用需求的，有清晰的对支持特性和用况的定义。 
2. 它们都简洁，易懂。我们往往发现越是直观的面向对象设计越是简单，容易维护。原因在于直观的面向对象设计正是参考我们熟知的真实世界进行类的组织的。真实世界中不同对象间往往有着清晰的关系和弱耦合性。参考真实世界进行的面向对象设计更加简单，易于维护。
3. 它们都便于拆分进行单元测试。凡是上一定规模的程序，都不可能一气呵成，往往需要从底至上的开发。对于软件栈进行分层，有利于针对每层的开发进行单元测试。比如我们在做GPU软件设计的时候往往有类似划分:硬件层 / Driver层 / CUDA 库 / 操作与数据模块层 / 应用层。其中只有CUDA 库涉及到CUDA 相关API的调用，和kernel计算。

## 如何设计GPU程序
### 充分理解算法
充分理解算法经常是一些开发者容易忽略的一个问题，很多开发者急于开始动手写程序而不去理解算法。
这里充分理解算法并不是说掌握了公式，网络模型就算是理解算法了。
理解算法后应当给出合理的建议从算法层次上进行优化，从而避免冗余的或者非合并的计算。举个例子：LSTM每一层/时间步的操作可以简化为两个矩阵相乘+一个逐点计算。而实际上由于依赖关系问题，在同一个斜面上的节点（比如第一层的第二个时间步和第二层的第一个时间步）可以同时计算，进而可以合并。
### 如何评估GPU可能带来的性能收益
评估GPU可能带来的性能收益往往是项目发起者，或者上级领导经常会问的一个问题。但实际上这个问题即使对于资深开发者也不是很容易回答。
大概有如下几种方法进行评估：
1. 假设移植到GPU的部分加速效果非常理想（移植后的程序此部分耗时为0），那么整个程序的性能是否让你满意？如果这都无法让你满意，也就没有必要进行移植了，或者尝试寻找其他可以优化的点。
2. 假设移植到GPU的部分可以把GPU的计算能力发挥到极致（达到理论计算峰值和带宽），那么整个程序的性能是否让你满意？
3. 尝试先花较短时间设计一个原型，用来评估可能的性能。这个原型不一定计算出的数值正确，但至少运行了主要的计算部分。
### 对于开发周期的预估
这里比较难一概而论，这往往和开发人员本身的素质是密切相关的。对于一个熟练掌握GPU和相关库开发的工程师来说可能简单的事情对于新手来说可能非常困难。从我的经验来看新手往往在刚开始学习CUDA两个月之内无法编写出性能合理的GPU程序。在这里比较合理的做法是让开发工程师写出具体的开发步骤，然后逐项和工程师一同讨论，进行时间的评估，充分参考工程师本人的意见。你如果不相信你的工程师，你能相信谁呢？
### 如何选择GPU平台
在项目开始之初应该明确未来使用的GPU平台，最好开发工作就在这个GPU平台上开发。
因为平台不一样程序的热点，瓶颈可能完全不同。直接影响优化的有效性。
这里只说Telsa GPU的选择规律（实际如涉及其他产品线可能还要分析价格等因素）：
1. 大卡训练小卡线上部署：小卡往往具有性能功耗比优势，但大卡由于可达到更高的单节点内的计算速度，所以可以尽量减少训练所需的GPU，从而达到减少通信损耗的目的。
2. 训练一般选择高密度服务器：一机八卡比两机四卡训练速度快，因为可以避免主机间通信
3. 训练一般选择NVLink服务器或者多GPU挂在同一个socket下的服务器:支持GPU间P2P通信
4. inferencce 一般选择多个GPU挂在不同socket下：保证充足的CPU/内存带宽，支持每个GPU的推理
### GPU实现方案之算法设计

### GPU实现方法之内存设计
### GPU实现需要注意哪些问题
### 基于深度学习的GPU产品开发是最简单的GPU项目


什么人适合从事GPU开发工作；如何管理基于GPU的项目进度；

