---
layout: post
title: 基于GPU的深度学习应用设计
---
## 这篇文章写给哪些人
你是一个正要开始开发基于NVIDIA GPU的深度学习产品的工程师。或者已经开始开发，但是愿意回过头来重新审视自己在程序设计阶段可能存在的问题。
你将在这篇文章中了解到：好的GPU程序设计可以给我们带来什么，或者，哪些问题是可以在GPU程序设计阶段回避的；GPU程序设计阶段要考虑哪些问题；如何考虑这些问题。

你是一个正在领导深度学习产品开发的经理，并且对NVIDIA GPU的解决方案并不排斥。
你将在这篇文章中了解到：如何评估GPU可能为这个产品带来的提升；如何选出最适合于这个项目的GPU实现方案。

## 程序设计是最重要的一步，尤其对于GPU程序
我们在支持用户进行GPU相关程序开发的时候，往往会面对一些完成度很高的糟糕的实现。这些糟糕的实现往往从设计上讲就是糟糕的，比如我们总会看到循环内b部出现的内存分配（减少模块间耦合性），总会看到几百个线程的kernel（比把一些计算合并更容易实现和便于理解），总会看到一些不打batch的DNN实现（程序灵活性高，容易适配原来的CPU设计）。开发者对这些错误的设计辩护时，往往理由充分。但是，我们之所以将程序迁移到GPU，难道不是为了提高性能吗？
这些实现由于对底层实现进行了多层的封装，或者代码庞大，让我们在优化的时候感到无从下手。想要将这类应用优化到合理的水平往往需要大刀阔斧的修改，有时候甚至和重写一遍没有太大区别。

所以，那些最严重的性能问题往往都和程序设计阶段的错误有关。

GPU和CPU从硬件上有明显的区别，这些区别使得一些糟糕的程序设计可以带来极大地性能问题。举个例子:Tesla P4上YOLO Tiny的inference频率可以达到~1000fps,但是一个多余的内存分配和释放（与主机中总共显存空间，内存空间，同时调用的cudaMalloc/cudaFree的数量有关系）甚至可以达到上百毫秒。一个简单的kernel 调用，比如小图片的YUV-RGB的转换时间可能在几个微妙，但是一个kernel调用所需要的准备时间（CPU上）可以达到十几个微妙，在Tegra上甚至可以达到几十上百微秒。

所以，程序设计对整个GPU程序的性能极其重要。

## 什么是优秀的GPU程序设计
### 优秀GPU程序设计的一些共同特征
1. 优秀的GPU程序设计往往只在程序运行之初分配资源（内存，显存，创建Handle，stream等）和进行初始化操作。如果你使用面向对象的设计，就是在构造函数中进行分配和初始化。面向对象的设计可以让GPU程序设计思路更清楚也更简单。
2. 相对的，优秀的程序设计往往只在程序运行结尾进行资源的释放。比如析构函数中。
3. 优秀的程序设计往往充分考虑到GPU的并行计算优势，让每一次计算（Kernel调用）完成更多的数据处理（本质上分配更多的并行线程）。比如对于DNN来说，是打batch进行处理，同时也可以合并多个不相关的layer进行计算（参考TensorRT的特性）。对于矩阵计算就是多个同size的小矩阵一起计算。对于网格计算，就是每个GPU上分配更多网格。
4. 优秀的程序设计往往使用优化方式对数据进行存储（参考Best Practice Guide中对于合并访问的解释）。比如对于矩阵相乘来说NT的性能往往好于NN。

### 优秀的GPU程序设计也是优秀的程序设计。
在众多方面优秀的GPU程序设计和我们熟知的CPU程序设计有着很多共性。
1. 它们都是充分考虑应用需求的，有清晰的对支持特性和用况的定义。 
2. 它们都简洁，易懂。我们往往发现越是直观的面向对象设计越是简单，容易维护。原因在于直观的面向对象设计正是参考我们熟知的真实世界进行类的组织的。真实世界中不同对象间往往有着清晰的关系和弱耦合性。参考真实世界进行的面向对象设计更加简单，易于维护。
3. 它们都便于拆分进行单元测试。凡是上一定规模的程序，都不可能一气呵成，往往需要从底至上的开发。对于软件栈进行分层，有利于针对每层的开发进行单元测试。比如我们在做GPU软件设计的时候往往有类似划分:硬件层 / Driver层 / CUDA 库 / 操作与数据模块层 / 应用层。其中只有CUDA 库涉及到CUDA 相关API的调用，和kernel计算。

## 如何设计GPU程序
### 充分理解算法
### 如何评估GPU可能带来的性能收益
### 对于开发周期的预估
### 如何选择GPU平台
### GPU实现方案之算法设计
### GPU实现方法之内存设计
### GPU实现需要注意哪些问题
### 基于深度学习的GPU产品开发是最简单的GPU项目


什么人适合从事GPU开发工作；如何管理基于GPU的项目进度；

